{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CoronarySmallDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "        \n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "        \n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_RGBA2RGB)\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_image_dir = 'images_train\\input'\n",
    "train_mask_dir = 'images_train\\output'\n",
    "val_image_dir = 'images_val\\input'\n",
    "val_mask_dir = 'images_val\\output'\n",
    "test_image_dir = 'images_test\\input'\n",
    "test_mask_dir = 'images_test\\output'\n",
    "\n",
    "train_dataset = CoronarySmallDataset(train_image_dir, train_mask_dir, transform=transform)\n",
    "val_dataset = CoronarySmallDataset(val_image_dir, val_mask_dir, transform=transform)\n",
    "test_dataset = CoronarySmallDataset(test_image_dir, test_mask_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=12, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=12, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medium_RGB_model import UNet\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, masks in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # print(images.size())\n",
    "            # print(images)\n",
    "            # print(masks.size())\n",
    "            # print(masks)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            # print(outputs.size())\n",
    "            # print(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'medium_RGB_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:41<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.6180, Val Loss: 0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:50<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/35, Train Loss: 0.5500, Val Loss: 0.5329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:48<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35, Train Loss: 0.5161, Val Loss: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:49<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35, Train Loss: 0.4883, Val Loss: 0.4749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:50<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35, Train Loss: 0.4631, Val Loss: 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:51<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35, Train Loss: 0.4389, Val Loss: 0.4266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:52<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/35, Train Loss: 0.4156, Val Loss: 0.4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:55<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/35, Train Loss: 0.3932, Val Loss: 0.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:57<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/35, Train Loss: 0.3720, Val Loss: 0.3629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:07<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/35, Train Loss: 0.3519, Val Loss: 0.3456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:56<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/35, Train Loss: 0.3329, Val Loss: 0.3247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:50<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/35, Train Loss: 0.3145, Val Loss: 0.3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:49<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/35, Train Loss: 0.2968, Val Loss: 0.2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:50<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/35, Train Loss: 0.2798, Val Loss: 0.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:52<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/35, Train Loss: 0.2635, Val Loss: 0.2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:50<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/35, Train Loss: 0.2479, Val Loss: 0.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:51<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/35, Train Loss: 0.2338, Val Loss: 0.2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:49<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35, Train Loss: 0.2207, Val Loss: 0.2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:53<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/35, Train Loss: 0.2086, Val Loss: 0.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:49<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/35, Train Loss: 0.1975, Val Loss: 0.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:49<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/35, Train Loss: 0.1871, Val Loss: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:03<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/35, Train Loss: 0.1772, Val Loss: 0.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:03<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/35, Train Loss: 0.1677, Val Loss: 0.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/35, Train Loss: 0.1589, Val Loss: 0.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/35, Train Loss: 0.1506, Val Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:12<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35, Train Loss: 0.1428, Val Loss: 0.1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:12<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/35, Train Loss: 0.1355, Val Loss: 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:55<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/35, Train Loss: 0.1287, Val Loss: 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:54<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35, Train Loss: 0.1222, Val Loss: 0.1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:56<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35, Train Loss: 0.1163, Val Loss: 0.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:01<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/35, Train Loss: 0.1108, Val Loss: 0.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:04<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/35, Train Loss: 0.1057, Val Loss: 0.1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:11<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/35, Train Loss: 0.1009, Val Loss: 0.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:19<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/35, Train Loss: 0.0966, Val Loss: 0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:22<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.0923, Val Loss: 0.0946\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('medium_RGB_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "def show_image(type, image_name):\n",
    "    dir = f\"images_test\\{type}\"\n",
    "    print(dir)\n",
    "    img = cv2.imread(os.path.join(dir, image_name), cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    cv2.imshow(type, img)\n",
    "\n",
    "def predict(image_name):\n",
    "    dir = 'images_test\\input'\n",
    "    img = cv2.imread(os.path.join(dir, image_name), cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "        print(pred)\n",
    "        # pred = (pred > 0.5).astype(np.uint8)\n",
    "    R, G, B = pred[0], pred[1], pred[2]\n",
    "    # cv2.imshow('R', R)\n",
    "    # cv2.imshow('G', G)\n",
    "    # cv2.imshow('B', B)\n",
    "    pred_image = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "    pred_image[..., 0] = (R * 255).astype(np.uint8)\n",
    "    pred_image[..., 1] = (G * 255).astype(np.uint8)\n",
    "    pred_image[..., 2] = (B * 255).astype(np.uint8)\n",
    "    print(pred_image)\n",
    "    cv2.imshow('pred', pred_image)\n",
    "    cv2.waitKey(0)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_test\\input\n",
      "images_test\\output\n",
      "[[[0.06246718 0.06922256 0.05895988 ... 0.04856448 0.05051027 0.07822076]\n",
      "  [0.06767297 0.0582726  0.07724336 ... 0.05335322 0.06814187 0.0592076 ]\n",
      "  [0.05244011 0.05740533 0.05688231 ... 0.05359422 0.05517795 0.08688217]\n",
      "  ...\n",
      "  [0.05954779 0.04912103 0.07220041 ... 0.05501693 0.05996656 0.05422998]\n",
      "  [0.04936417 0.05736936 0.05567563 ... 0.05995795 0.0517322  0.09486095]\n",
      "  [0.07306532 0.05651188 0.07467362 ... 0.05443484 0.07152171 0.05348182]]\n",
      "\n",
      " [[0.0813878  0.10738065 0.07746644 ... 0.08434334 0.09520651 0.11754666]\n",
      "  [0.10931675 0.0880686  0.11334766 ... 0.07558413 0.09863579 0.0964295 ]\n",
      "  [0.06609856 0.07112847 0.07200418 ... 0.06606143 0.07336381 0.09913124]\n",
      "  ...\n",
      "  [0.10077146 0.06965933 0.10016512 ... 0.0798332  0.07984433 0.08416903]\n",
      "  [0.06911609 0.07294392 0.07583224 ... 0.07108422 0.07475418 0.11453338]\n",
      "  [0.12801865 0.08403397 0.10762579 ... 0.07158974 0.11191987 0.09133819]]\n",
      "\n",
      " [[0.0566926  0.05854304 0.05554635 ... 0.05666994 0.05073081 0.06849002]\n",
      "  [0.06952627 0.05913426 0.06565581 ... 0.05052875 0.06074065 0.06017058]\n",
      "  [0.05235999 0.05275991 0.0524006  ... 0.04287499 0.05602554 0.07161326]\n",
      "  ...\n",
      "  [0.06394749 0.05252375 0.06234632 ... 0.05244376 0.05839097 0.05211062]\n",
      "  [0.05458868 0.05267576 0.05707793 ... 0.05179342 0.05444733 0.08510116]\n",
      "  [0.09177949 0.05705909 0.07908616 ... 0.05526192 0.06508119 0.06158536]]]\n",
      "[[[15 20 14]\n",
      "  [17 27 14]\n",
      "  [15 19 14]\n",
      "  ...\n",
      "  [12 21 14]\n",
      "  [12 24 12]\n",
      "  [19 29 17]]\n",
      "\n",
      " [[17 27 17]\n",
      "  [14 22 15]\n",
      "  [19 28 16]\n",
      "  ...\n",
      "  [13 19 12]\n",
      "  [17 25 15]\n",
      "  [15 24 15]]\n",
      "\n",
      " [[13 16 13]\n",
      "  [14 18 13]\n",
      "  [14 18 13]\n",
      "  ...\n",
      "  [13 16 10]\n",
      "  [14 18 14]\n",
      "  [22 25 18]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[15 25 16]\n",
      "  [12 17 13]\n",
      "  [18 25 15]\n",
      "  ...\n",
      "  [14 20 13]\n",
      "  [15 20 14]\n",
      "  [13 21 13]]\n",
      "\n",
      " [[12 17 13]\n",
      "  [14 18 13]\n",
      "  [14 19 14]\n",
      "  ...\n",
      "  [15 18 13]\n",
      "  [13 19 13]\n",
      "  [24 29 21]]\n",
      "\n",
      " [[18 32 23]\n",
      "  [14 21 14]\n",
      "  [19 27 20]\n",
      "  ...\n",
      "  [13 18 14]\n",
      "  [18 28 16]\n",
      "  [13 23 15]]]\n"
     ]
    }
   ],
   "source": [
    "# image_name = \"13c2ur549vohc0jat2dvu3xs7q1_18.png\"\n",
    "# image_name = \"13c2ur549vohc0jat2wd23me01_25.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49h4bhdjeabmt22_31.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49juwu7plj9dv22_40.png\"\n",
    "show_image(\"input\", image_name)\n",
    "show_image(\"output\", image_name)\n",
    "predict(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5773\n",
      "Mean Dice Coefficient: 0.6904\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('medium_RGB_model.pth'))\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = y_true.view(-1)\n",
    "    y_pred_f = y_pred.view(-1)\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "dice_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        dice_scores.append(dice_coefficient(masks, outputs))\n",
    "\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "mean_dice = torch.mean(torch.tensor(dice_scores))\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Mean Dice Coefficient: {mean_dice:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "def post_process(prediction):\n",
    "    prediction_np = prediction.cpu().numpy()\n",
    "    processed = morphology.remove_small_objects(prediction_np > 0.5, min_size=100)\n",
    "    processed = morphology.remove_small_holes(processed, area_threshold=100)\n",
    "    return torch.tensor(processed, device=device)\n",
    "\n",
    "post_processed_predictions = [post_process(pred) for pred in outputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    file = request.files['image']\n",
    "    img_bytes = file.read()\n",
    "    img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    img = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "        pred = (pred > 0.5).astype(np.uint8)\n",
    "    \n",
    "    _, buffer = cv2.imencode('.png', pred)\n",
    "    response = io.BytesIO(buffer)\n",
    "    response.seek(0)\n",
    "    return response, 200, {'Content-Type': 'image/png'}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
