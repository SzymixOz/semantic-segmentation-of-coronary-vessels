{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class CoronarySmallDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        SIZE = 384\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "        \n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
    "        image = cv2.resize(image, (SIZE, SIZE), cv2.INTER_NEAREST)\n",
    "        \n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        # mask = cv2.cvtColor(mask, cv2.COLOR_RGBA2RGB)\n",
    "        mask = cv2.resize(mask, (SIZE, SIZE), cv2.INTER_NEAREST)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            # mask = self.transform(mask)\n",
    "            mask = torch.tensor(mask, dtype=torch.long)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_image_dir = '..\\images\\images_train\\input'\n",
    "train_mask_dir = '..\\images\\images_train\\output'\n",
    "val_image_dir = '..\\images\\images_val\\input'\n",
    "val_mask_dir = '..\\images\\images_val\\output'\n",
    "test_image_dir = '..\\images\\images_test\\input'\n",
    "test_mask_dir = '..\\images\\images_test\\output'\n",
    "\n",
    "train_dataset = CoronarySmallDataset(train_image_dir, train_mask_dir, transform=transform)\n",
    "val_dataset = CoronarySmallDataset(val_image_dir, val_mask_dir, transform=transform)\n",
    "test_dataset = CoronarySmallDataset(test_image_dir, test_mask_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter_RGB import convert_int_to_RGB\n",
    "from large_RGB_model import UNet\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet()\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model_binary_6.pth'))\n",
    "model.eval()\n",
    "\n",
    "def show_image(type, image_name):\n",
    "    dir = f\"..\\images\\images_test\\{type}\"\n",
    "    print(dir)\n",
    "    if type == 'output':\n",
    "        img = cv2.imread(os.path.join(dir, image_name), cv2.IMREAD_UNCHANGED)\n",
    "        # img = img[:, :, 2]\n",
    "        print(\"Oryginalnie: \", np.unique(img))\n",
    "        \n",
    "        # print(\"Po resize: NEAREST\\t  \", np.unique(cv2.resize(img, (256, 256), interpolation=cv2.INTER_NEAREST)))\n",
    "        # cv2.imshow('INTER_NEAREST', cv2.resize(convert_int_to_RGB(cv2.resize(img, (256, 256), interpolation=cv2.INTER_NEAREST)), (512, 512)))\n",
    "        # print(\"Po resize: NEAREST_EXACT  \", np.unique(cv2.resize(img, (256, 256), interpolation=cv2.INTER_NEAREST_EXACT)))\n",
    "        # cv2.imshow('INTER_NEAREST_EXACT', cv2.resize(convert_int_to_RGB(cv2.resize(img, (256, 256), interpolation=cv2.INTER_NEAREST_EXACT)), (512, 512)))\n",
    "        \n",
    "        print(\"Po resize:  \", np.unique(cv2.resize(img, (256, 256))))\n",
    "        # print(img)\n",
    "        img = convert_int_to_RGB(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(dir, image_name), cv2.IMREAD_UNCHANGED)\n",
    "        img = img * 7\n",
    "    # img = cv2.resize(img, (256, 256))\n",
    "    # np.set_printoptions(threshold=np.inf)\n",
    "    cv2.imshow(type, img)\n",
    "\n",
    "def predict(image_name):\n",
    "    dir = '..\\images\\images_test\\input'\n",
    "    img = cv2.imread(os.path.join(dir, image_name), cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model.predict(img)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "    print(\"Z sieci:    \", np.unique(pred))\n",
    "\n",
    "    pred_image = convert_int_to_RGB(pred)\n",
    "    pred_image = cv2.resize(pred_image, (512, 512))\n",
    "    pred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('pred', pred_image)\n",
    "    cv2.waitKey(0)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\images\\images_test\\input\n",
      "..\\images\\images_test\\output\n",
      "Oryginalnie:  [ 0  5  6  7  8  9 10 11 13 15 16 17]\n",
      "Po resize:   [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "Z sieci:     [ 0  5  6  7  8  9 13 15 17 18]\n"
     ]
    }
   ],
   "source": [
    "# image_name = \"131aedfhs6pnf1fvtvp49mhdb2fucqzo22_29.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49mld7mqexnz322_36.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49mia892s56cf22_28.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49juwu7plj9dv22_40.png\"\n",
    "# image_name = \"13c2ur549vohc0jat2dvu3xs7q1_18.png\"\n",
    "image_name = \"131aedfhs6pnf1fvtvp49mi8hml81goj22_37.png\"\n",
    "\n",
    "# treningowe\n",
    "# image_name = \"13c2ur549vohc0jat2e6y42xk11_31.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49jstof8iams322_36.png\"\n",
    "# image_name = \"131aedfhs6pnf1fvtvp49mff2plx3rdw22_24.png\"\n",
    "show_image(\"input\", image_name)\n",
    "show_image(\"output\", image_name)\n",
    "predict(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    correct_clear = 0\n",
    "    total = 0\n",
    "    total_clear = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            preds = model.predict(images)\n",
    "            \n",
    "            correct += (preds == masks).sum().item()\n",
    "            correct_clear += (preds[masks != 0] == masks[masks != 0]).sum().item()\n",
    "            total += masks.numel()\n",
    "            total_clear += masks[masks != 0].numel()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy_clear = correct_clear / total_clear\n",
    "    return accuracy, accuracy_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.30%\n",
      "Train Accuracy Clear: 53.03%\n",
      "\n",
      "Validation Accuracy: 96.67%\n",
      "Validation Accuracy Clear: 44.19%\n",
      "\n",
      "Test Accuracy: 96.88%\n",
      "Test Accuracy Clear: 47.71%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('RGB_model_INTER_NEAREST.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "test_accuracy = compute_accuracy(model, test_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Test Accuracy: {test_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Test Accuracy Clear: {test_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.27%\n",
      "Train Accuracy Clear: 52.58%\n",
      "\n",
      "Validation Accuracy: 96.71%\n",
      "Validation Accuracy Clear: 44.91%\n",
      "\n",
      "Test Accuracy: 96.83%\n",
      "Test Accuracy Clear: 47.04%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('RGB_model_INTER_NEAREST_EXACT.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "test_accuracy = compute_accuracy(model, test_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Test Accuracy: {test_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Test Accuracy Clear: {test_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 96.86%\n",
      "Train Accuracy Clear: 45.19%\n",
      "\n",
      "Validation Accuracy: 96.41%\n",
      "Validation Accuracy Clear: 39.84%\n",
      "\n",
      "Test Accuracy: 96.56%\n",
      "Test Accuracy Clear: 42.47%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('RGB_model_INTER_NEAREST_2.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "test_accuracy = compute_accuracy(model, test_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Test Accuracy: {test_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Test Accuracy Clear: {test_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.62%\n",
      "Train Accuracy Clear: 58.69%\n",
      "\n",
      "Validation Accuracy: 96.73%\n",
      "Validation Accuracy Clear: 45.27%\n",
      "\n",
      "Test Accuracy: 96.87%\n",
      "Test Accuracy Clear: 47.68%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('RGB_model_INTER_NEAREST_4.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "test_accuracy = compute_accuracy(model, test_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Test Accuracy: {test_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Test Accuracy Clear: {test_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do poprawy, teraz nie ma sensu\n",
    "# Musiałoby dla każdej klasu osobno liczyć\n",
    "def compute_precision_recall_f1(model, data_loader, device, num_classes=28):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            preds = model.predict(images)\n",
    "            \n",
    "            all_preds.append(preds.view(-1).cpu().numpy())\n",
    "            all_targets.append(masks.view(-1).cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    TP = np.zeros(num_classes)\n",
    "    FP = np.zeros(num_classes)\n",
    "    FN = np.zeros(num_classes)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP[i] = ((all_preds == i) & (all_targets == i)).sum()\n",
    "        FP[i] = ((all_preds == i) & (all_targets != i)).sum()\n",
    "        FN[i] = ((all_preds != i) & (all_targets == i)).sum()\n",
    "    \n",
    "    TP[0], FP[0], FN[0] = 0, 0, 0\n",
    "    print(TP, FP, FN)\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(TP.sum(), FP.sum(), FN.sum())\n",
    "\n",
    "    precision_weighted = TP.sum() / (TP.sum() + FP.sum())\n",
    "    recall_weighted = TP.sum() / (TP.sum() + FN.sum())\n",
    "    f1_weighted = 2 * precision_weighted * recall_weighted / (precision_weighted + recall_weighted)\n",
    "\n",
    "    return precision, recall, f1, precision_weighted, recall_weighted, f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0. 15586. 12986. 12656.  7401. 20870. 14879. 24071. 23392. 18106.\n",
      "     0.     0.     0. 11981.     0. 17432.   622. 17433.  1503.     0.\n",
      "     0.     0.  9909.     0.     0.     0.     0.     0.] [    0.  2475.  5335.  8036.  5821.  7171. 12622. 26610. 17918. 44918.\n",
      "     0.     0.     0. 12292.     0. 29694.   829. 14739. 10028.     0.\n",
      "     0.     0.  6100.     0.     0.     0.     0.     0.] [    0. 10739. 17024. 10015. 20247. 10543. 15879. 14955. 20045. 15704.\n",
      "  4589. 17316.  2691. 11314. 11600. 12858. 15827. 16219. 17236.    38.\n",
      "  1060.  1313.  1737.   584.   292.   128.   260.  2255.]\n",
      "208827.0 204588.0 252468.0\n",
      "Class 0: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 1: Precision: 86.30%, Recall: 59.21%, F1: 70.23%\n",
      "Class 2: Precision: 70.88%, Recall: 43.27%, F1: 53.74%\n",
      "Class 3: Precision: 61.16%, Recall: 55.82%, F1: 58.37%\n",
      "Class 4: Precision: 55.97%, Recall: 26.77%, F1: 36.22%\n",
      "Class 5: Precision: 74.43%, Recall: 66.44%, F1: 70.21%\n",
      "Class 6: Precision: 54.10%, Recall: 48.37%, F1: 51.08%\n",
      "Class 7: Precision: 47.50%, Recall: 61.68%, F1: 53.67%\n",
      "Class 8: Precision: 56.63%, Recall: 53.85%, F1: 55.20%\n",
      "Class 9: Precision: 28.73%, Recall: 53.55%, F1: 37.40%\n",
      "Class 10: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 11: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 12: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 13: Precision: 49.36%, Recall: 51.43%, F1: 50.37%\n",
      "Class 14: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 15: Precision: 36.99%, Recall: 57.55%, F1: 45.03%\n",
      "Class 16: Precision: 42.87%, Recall: 3.78%, F1: 6.95%\n",
      "Class 17: Precision: 54.19%, Recall: 51.80%, F1: 52.97%\n",
      "Class 18: Precision: 13.03%, Recall: 8.02%, F1: 9.93%\n",
      "Class 19: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 20: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 21: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 22: Precision: 61.90%, Recall: 85.09%, F1: 71.66%\n",
      "Class 23: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 24: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 25: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 26: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 27: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Average Precision: 28.358%\n",
      "Average Recall: 25.951%\n",
      "Average F1: 25.822%\n",
      "\n",
      "Weighted Precision: 50.513%\n",
      "Weighted Recall: 45.270%\n",
      "Weighted F1: 47.748%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Szymon\\AppData\\Local\\Temp\\ipykernel_10876\\531350562.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = TP / (TP + FP)\n",
      "C:\\Users\\Szymon\\AppData\\Local\\Temp\\ipykernel_10876\\531350562.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = TP / (TP + FN)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('RGB_model_INTER_NEAREST_4.pth'))\n",
    "precision, recall, f1, precision_weighted, recall_weighted, f1_weighted = compute_precision_recall_f1(model, val_loader, device)\n",
    "\n",
    "if np.isnan(precision).any():\n",
    "    precision = np.nan_to_num(precision)\n",
    "if np.isnan(recall).any():\n",
    "    recall = np.nan_to_num(recall)\n",
    "if np.isnan(f1).any():\n",
    "    f1 = np.nan_to_num(f1)\n",
    "\n",
    "for i in range(28):\n",
    "    print(f'Class {i}: Precision: {precision[i] * 100:.2f}%, Recall: {recall[i] * 100:.2f}%, F1: {f1[i] * 100:.2f}%')\n",
    "\n",
    "print(f'Average Precision: {np.mean(precision) * 100:.3f}%')\n",
    "print(f'Average Recall: {np.mean(recall) * 100:.3f}%')\n",
    "print(f'Average F1: {np.mean(f1) * 100:.3f}%')\n",
    "print()\n",
    "print(f'Weighted Precision: {precision_weighted * 100:.3f}%')\n",
    "print(f'Weighted Recall: {recall_weighted * 100:.3f}%')\n",
    "print(f'Weighted F1: {f1_weighted * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0. 19277. 19020. 16859. 20720. 24794. 17365. 20084. 23980. 17348.\n",
      "     0.  3630.     0. 11970.     0. 19163.   709. 21294.  1259.     0.\n",
      "     0.     0. 10302.     0.     0.     0.     0.     0.] [0.0000e+00 3.4870e+03 7.1750e+03 8.7380e+03 1.5142e+04 1.3561e+04\n",
      " 1.5346e+04 1.6963e+04 1.4623e+04 3.5201e+04 1.0000e+00 6.2280e+03\n",
      " 0.0000e+00 1.0571e+04 5.0000e+00 3.9228e+04 8.5600e+02 1.7074e+04\n",
      " 7.3190e+03 0.0000e+00 0.0000e+00 0.0000e+00 4.5400e+03 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00] [    0.  7048. 10990.  5812.  6928.  6619. 13393. 18942. 19457. 16462.\n",
      "  4589. 13686.  2691. 11325. 11600. 11127. 15740. 12358. 17480.    38.\n",
      "  1060.  1313.  1344.   584.   292.   128.   260.  2255.]\n",
      "247774.0 216059.0 213521.0\n",
      "Class 0: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 1: Precision: 84.68%, Recall: 73.23%, F1: 78.54%\n",
      "Class 2: Precision: 72.61%, Recall: 63.38%, F1: 67.68%\n",
      "Class 3: Precision: 65.86%, Recall: 74.36%, F1: 69.86%\n",
      "Class 4: Precision: 57.78%, Recall: 74.94%, F1: 65.25%\n",
      "Class 5: Precision: 64.64%, Recall: 78.93%, F1: 71.08%\n",
      "Class 6: Precision: 53.09%, Recall: 56.46%, F1: 54.72%\n",
      "Class 7: Precision: 54.21%, Recall: 51.46%, F1: 52.80%\n",
      "Class 8: Precision: 62.12%, Recall: 55.21%, F1: 58.46%\n",
      "Class 9: Precision: 33.01%, Recall: 51.31%, F1: 40.18%\n",
      "Class 10: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 11: Precision: 36.82%, Recall: 20.96%, F1: 26.72%\n",
      "Class 12: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 13: Precision: 53.10%, Recall: 51.38%, F1: 52.23%\n",
      "Class 14: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 15: Precision: 32.82%, Recall: 63.27%, F1: 43.22%\n",
      "Class 16: Precision: 45.30%, Recall: 4.31%, F1: 7.87%\n",
      "Class 17: Precision: 55.50%, Recall: 63.28%, F1: 59.13%\n",
      "Class 18: Precision: 14.68%, Recall: 6.72%, F1: 9.22%\n",
      "Class 19: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 20: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 21: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 22: Precision: 69.41%, Recall: 88.46%, F1: 77.79%\n",
      "Class 23: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 24: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 25: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 26: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Class 27: Precision: 0.00%, Recall: 0.00%, F1: 0.00%\n",
      "Average Precision: 30.559%\n",
      "Average Recall: 31.345%\n",
      "Average F1: 29.812%\n",
      "\n",
      "Weighted Precision: 53.419%\n",
      "Weighted Recall: 53.713%\n",
      "Weighted F1: 53.565%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Szymon\\AppData\\Local\\Temp\\ipykernel_10876\\531350562.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = TP / (TP + FP)\n",
      "C:\\Users\\Szymon\\AppData\\Local\\Temp\\ipykernel_10876\\531350562.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = TP / (TP + FN)\n",
      "C:\\Users\\Szymon\\AppData\\Local\\Temp\\ipykernel_10876\\531350562.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = 2 * precision * recall / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('large_RGB_model_dropout.pth'))\n",
    "precision, recall, f1, precision_weighted, recall_weighted, f1_weighted = compute_precision_recall_f1(model, val_loader, device)\n",
    "\n",
    "if np.isnan(precision).any():\n",
    "    precision = np.nan_to_num(precision)\n",
    "if np.isnan(recall).any():\n",
    "    recall = np.nan_to_num(recall)\n",
    "if np.isnan(f1).any():\n",
    "    f1 = np.nan_to_num(f1)\n",
    "    \n",
    "for i in range(28):\n",
    "    print(f'Class {i}: Precision: {precision[i] * 100:.2f}%, Recall: {recall[i] * 100:.2f}%, F1: {f1[i] * 100:.2f}%')\n",
    "\n",
    "print(f'Average Precision: {np.mean(precision) * 100:.3f}%')\n",
    "print(f'Average Recall: {np.mean(recall) * 100:.3f}%')\n",
    "print(f'Average F1: {np.mean(f1) * 100:.3f}%')\n",
    "print()\n",
    "print(f'Weighted Precision: {precision_weighted * 100:.3f}%')\n",
    "print(f'Weighted Recall: {recall_weighted * 100:.3f}%')\n",
    "print(f'Weighted F1: {f1_weighted * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.40%\n",
      "Train Accuracy Clear: 54.53%\n",
      "\n",
      "Validation Accuracy: 96.77%\n",
      "Validation Accuracy Clear: 45.99%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('model_binary_5.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.77%\n",
      "Train Accuracy Clear: 61.09%\n",
      "\n",
      "Validation Accuracy: 96.86%\n",
      "Validation Accuracy Clear: 47.45%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('model_binary_6.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.49%\n",
      "Train Accuracy Clear: 56.02%\n",
      "\n",
      "Validation Accuracy: 96.76%\n",
      "Validation Accuracy Clear: 45.81%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('model_binary_7.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.52%\n",
      "Train Accuracy Clear: 55.89%\n",
      "\n",
      "Validation Accuracy: 96.75%\n",
      "Validation Accuracy Clear: 44.85%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('model_binary_8.pth'))\n",
    "\n",
    "train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Train Accuracy Clear: {train_accuracy[1] * 100 :.2f}%')\n",
    "print()\n",
    "print(f'Validation Accuracy: {val_accuracy[0] * 100 :.2f}%')\n",
    "print(f'Validation Accuracy Clear: {val_accuracy[1] * 100 :.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
